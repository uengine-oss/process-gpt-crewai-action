from contextvars import ContextVar
from typing import Optional, Any
import json
import asyncio
import openai
from utils.logger import handle_error, log

todo_id_var: ContextVar[Optional[int]] = ContextVar('todo_id', default=None)
proc_id_var: ContextVar[Optional[str]] = ContextVar('proc_inst_id', default=None)

# ============================================================================
# ìš”ì•½ ì²˜ë¦¬
# ============================================================================

async def summarize_async(outputs: Any, feedbacks: Any, drafts: Any = None) -> tuple[str, str]:
    """LLMìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ - ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë³„ë„ ë°˜í™˜ (ë¹„ë™ê¸°)"""
    try:
        log("ìš”ì•½ì„ ìœ„í•œ LLM ë³‘ë ¬ í˜¸ì¶œ ì‹œì‘")
        
        # ë°ì´í„° ì¤€ë¹„
        outputs_str = _convert_to_string(outputs)
        feedbacks_str = _convert_to_string(feedbacks)
        
        # ë³‘ë ¬ ì²˜ë¦¬
        output_summary, feedback_summary = await _summarize_parallel(outputs_str, feedbacks_str)
        
        log(f"ì´ì „ê²°ê³¼ ìš”ì•½ ì™„ë£Œ: {len(output_summary)}ì, í”¼ë“œë°± ìš”ì•½ ì™„ë£Œ: {len(feedback_summary)}ì")
        return output_summary, feedback_summary
        
    except Exception as e:
        handle_error("ìš”ì•½ì²˜ë¦¬", e)
        return "", ""

async def _summarize_parallel(outputs_str: str, feedbacks_str: str) -> tuple[str, str]:
    """ë³‘ë ¬ë¡œ ìš”ì•½ ì²˜ë¦¬ - ë³„ë„ ë°˜í™˜"""
    tasks = []
    
    # 1. ì´ì „ ê²°ê³¼ë¬¼ ìš”ì•½ íƒœìŠ¤í¬ (ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ)
    if outputs_str and outputs_str.strip():
        output_prompt = _create_output_summary_prompt(outputs_str)
        tasks.append(_call_openai_api_async(output_prompt, "ì´ì „ ê²°ê³¼ë¬¼"))
    else:
        tasks.append(_create_empty_task(""))
    
    # 2. í”¼ë“œë°± ìš”ì•½ íƒœìŠ¤í¬ (ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ)
    if feedbacks_str and feedbacks_str.strip():
        feedback_prompt = _create_feedback_summary_prompt(feedbacks_str)
        tasks.append(_call_openai_api_async(feedback_prompt, "í”¼ë“œë°±"))
    else:
        tasks.append(_create_empty_task(""))
    
    # 3. ë‘ íƒœìŠ¤í¬ë¥¼ ë™ì‹œì— ì‹¤í–‰í•˜ê³  ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
    output_summary, feedback_summary = await asyncio.gather(*tasks)
    
    # 4. ë³„ë„ë¡œ ë°˜í™˜
    return output_summary, feedback_summary

async def _create_empty_task(result: str) -> str:
    """ë¹ˆ íƒœìŠ¤í¬ ìƒì„± (ì¦‰ì‹œ ì™„ë£Œ)"""
    return result

def _convert_to_string(data: Any) -> str:
    """ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if isinstance(data, str):
        return data
    return json.dumps(data, ensure_ascii=False)

def _create_output_summary_prompt(outputs_str: str) -> str:
    """ì´ì „ ê²°ê³¼ë¬¼ ìš”ì•½ í”„ë¡¬í”„íŠ¸ - ìƒì„¸ ë²„ì „"""
    return f"""ë‹¤ìŒì€ ì´ì „ ì‘ì—…ì—ì„œ ìƒì„±ëœ ê²°ê³¼ë¬¼ì…ë‹ˆë‹¤. ì´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ìš”ì•½í•´ì£¼ì„¸ìš”.

**ì´ì „ ì‘ì—… ê²°ê³¼ë¬¼:**
{outputs_str}

**ë¶„ì„ ë° ìš”ì•½ ì§€ì¹¨:**

1. **í•µì‹¬ ë‚´ìš© íŒŒì•…:**
   - ìˆ˜í–‰ëœ ì£¼ìš” ì‘ì—…ì´ë‚˜ ì—…ë¬´ëŠ” ë¬´ì—‡ì¸ê°€?
   - ë‹¬ì„±í•œ ëª©í‘œë‚˜ ì™„ë£Œëœ ë‹¨ê³„ëŠ” ë¬´ì—‡ì¸ê°€?
   - ìƒì„±ëœ ê²°ê³¼ë¬¼ì˜ ì£¼ìš” íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€?

2. **êµ¬ì²´ì  ë°ì´í„° ì¶”ì¶œ:**
   - ìˆ˜ì¹˜, ë‚ ì§œ, ì‹œê°„, ê¸ˆì•¡ ë“± êµ¬ì²´ì  ì •ë³´
   - ê°œìˆ˜, í¬ê¸°, ë¹„ìœ¨ ë“± ì •ëŸ‰ì  ë°ì´í„°
   - ì´ë¦„, ì œëª©, íŒŒì¼ëª… ë“± ê³ ìœ  ì‹ë³„ì

3. **ì¤‘ìš” ê²°ê³¼ ë° ì„±ê³¼:**
   - ì™„ì„±ëœ ë¬¸ì„œ, ì½”ë“œ, ë””ìì¸ ë“±ì˜ ì‚°ì¶œë¬¼
   - í•´ê²°ëœ ë¬¸ì œë‚˜ ê°œì„ ëœ ì‚¬í•­
   - ê²€ì¦ëœ ê²°ê³¼ë‚˜ í…ŒìŠ¤íŠ¸ ì„±ê³¼

4. **í˜„ì¬ ìƒíƒœ ë° ì§„í–‰ë„:**
   - ì „ì²´ í”„ë¡œì íŠ¸ì—ì„œ í˜„ì¬ ìœ„ì¹˜
   - ì™„ë£Œëœ ë¶€ë¶„ê³¼ ë‚¨ì€ ì‘ì—…
   - ë‹¤ìŒ ë‹¨ê³„ë¡œ ì—°ê²°ë˜ëŠ” ìš”ì†Œ

**ìš”ì•½ í˜•ì‹:**
ğŸ“‹ **ì´ì „ ì‘ì—… ê²°ê³¼ ìš”ì•½**

**ğŸ¯ ì£¼ìš” ì„±ê³¼:**
â€¢ [í•µì‹¬ ë‹¬ì„± ì‚¬í•­]
â€¢ [ì™„ë£Œëœ ì£¼ìš” ì‘ì—…]
â€¢ [ìƒì„±ëœ í•µì‹¬ ê²°ê³¼ë¬¼]

**ğŸ“Š êµ¬ì²´ì  ë°ì´í„°:**
â€¢ [ì¤‘ìš”í•œ ìˆ˜ì¹˜ë‚˜ ë°ì´í„°]
â€¢ [ë‚ ì§œ, ì‹œê°„ ë“± êµ¬ì²´ì  ì •ë³´]
â€¢ [ì •ëŸ‰ì  ì„±ê³¼ ì§€í‘œ]

**ğŸ“ˆ í˜„ì¬ ì§„í–‰ ìƒí™©:**
â€¢ [ì™„ë£Œëœ ë‹¨ê³„]
â€¢ [í˜„ì¬ í”„ë¡œì íŠ¸ ìƒíƒœ]
â€¢ [ë‹¤ìŒ ë‹¨ê³„ ì—°ê²°ì ]

**ìš”ì•½ ì›ì¹™:**
- ê°ê´€ì  ì‚¬ì‹¤ë§Œ ê¸°ë¡í•˜ê³  ì¶”ì¸¡í•˜ì§€ ì•ŠìŒ
- ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë¦¬í•˜ë˜ ëˆ„ë½ ì—†ì´ í¬í•¨
- 2000ì ì´ë‚´ë¡œ ê°„ê²°í•˜ë˜ í•µì‹¬ì€ ëª¨ë‘ í¬í•¨
- ë‹¤ìŒ ì‘ì—…ìê°€ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ëª…í™•í•˜ê²Œ ì‘ì„±"""

def _create_feedback_summary_prompt(feedbacks_str: str) -> str:
    """í”¼ë“œë°± ìš”ì•½ í”„ë¡¬í”„íŠ¸ - ìƒì„¸ ë²„ì „"""
    return f"""ë‹¤ìŒì€ ì´ì „ ì‘ì—… ê²°ê³¼ì— ëŒ€í•œ í”¼ë“œë°±ì…ë‹ˆë‹¤. ì´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

**í”¼ë“œë°± ë‚´ìš©:**
{feedbacks_str}

**ë¶„ì„ ë° ì •ë¦¬ ì§€ì¹¨:**

1. **í”¼ë“œë°± ìœ í˜• ë¶„ë¥˜:**
   - ê¸ì •ì  í‰ê°€: ë§Œì¡±ìŠ¤ëŸ¬ìš´ ë¶€ë¶„, ì˜ëœ ì 
   - ê°œì„  ìš”ì²­: ìˆ˜ì •ì´ë‚˜ ë³´ì™„ì´ í•„ìš”í•œ ë¶€ë¶„
   - ì¶”ê°€ ìš”êµ¬: ìƒˆë¡œìš´ ê¸°ëŠ¥ì´ë‚˜ ë‚´ìš© ì¶”ê°€ ìš”ì²­
   - ë°©í–¥ ë³€ê²½: ì ‘ê·¼ ë°©ì‹ì´ë‚˜ ì „ëµì˜ ë³€ê²½ ìš”êµ¬

2. **êµ¬ì²´ì  ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ:**
   - ëª…í™•í•œ ì§€ì‹œì‚¬í•­ì´ë‚˜ ìš”ì²­ì‚¬í•­
   - íŠ¹ì • ìˆ˜ì •ì´ë‚˜ ë³€ê²½ì´ í•„ìš”í•œ ë¶€ë¶„
   - êµ¬ì²´ì ì¸ ê¸°ì¤€ì´ë‚˜ ì¡°ê±´ ì œì‹œ
   - ì¼ì •ì´ë‚˜ ìš°ì„ ìˆœìœ„ ê´€ë ¨ ìš”êµ¬

3. **ë¬¸ì œì  ë° ê°œì„ ì‚¬í•­:**
   - ì§€ì ëœ ë¬¸ì œë‚˜ ë¶€ì¡±í•œ ë¶€ë¶„
   - ê¸°ëŒ€í–ˆë˜ ê²ƒê³¼ ë‹¤ë¥¸ ê²°ê³¼
   - í’ˆì§ˆì´ë‚˜ ì™„ì„±ë„ ê´€ë ¨ ì´ìŠˆ
   - ì‚¬ìš©ì„±ì´ë‚˜ ì‹¤ìš©ì„± ë¬¸ì œ

4. **í–¥í›„ ì‘ì—… ë°©í–¥:**
   - ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ë°˜ì˜í•´ì•¼ í•  ì‚¬í•­
   - ì „ì²´ì ì¸ ë°©í–¥ì„± ì¡°ì • í•„ìš”ì„±
   - ì¤‘ì ì ìœ¼ë¡œ ê°œì„ í•´ì•¼ í•  ì˜ì—­
   - ì¶”ê°€ ê²€í† ë‚˜ í™•ì¸ì´ í•„ìš”í•œ ë¶€ë¶„

**ìš”ì•½ í˜•ì‹:**
ğŸ’¬ **í”¼ë“œë°± ë¶„ì„ ìš”ì•½**

**ğŸ‘ ê¸ì •ì  í‰ê°€:**
â€¢ [ì˜ëœ ì ê³¼ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ë¶€ë¶„]
â€¢ [ìœ ì§€í•´ì•¼ í•  ìš”ì†Œ]

**ğŸ”§ êµ¬ì²´ì  ê°œì„  ìš”êµ¬:**
â€¢ [ëª…í™•í•œ ìˆ˜ì • ì§€ì‹œì‚¬í•­]
â€¢ [ì¶”ê°€í•´ì•¼ í•  ê¸°ëŠ¥ì´ë‚˜ ë‚´ìš©]
â€¢ [ë³€ê²½ì´ í•„ìš”í•œ ì ‘ê·¼ ë°©ì‹]

**âš ï¸ ì£¼ìš” ë¬¸ì œì :**
â€¢ [ì§€ì ëœ í•µì‹¬ ë¬¸ì œ]
â€¢ [ë¶€ì¡±í•˜ê±°ë‚˜ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„]
â€¢ [ê¸°ëŒ€ì™€ ë‹¤ë¥¸ ê²°ê³¼]

**ğŸ¯ í–¥í›„ ì‘ì—… ë°©í–¥:**
â€¢ [ë‹¤ìŒ ë‹¨ê³„ ìš°ì„ ìˆœìœ„]
â€¢ [ì¤‘ì  ê°œì„  ì˜ì—­]
â€¢ [ì „ì²´ì ì¸ ë°©í–¥ì„± ì¡°ì •ì‚¬í•­]

**ì‹¤í–‰ ì§€ì¹¨:**
- ê° í”¼ë“œë°±ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œìœ¼ë¡œ ë³€í™˜
- ìš°ì„ ìˆœìœ„ì™€ ì¤‘ìš”ë„ë¥¼ ëª…í™•íˆ êµ¬ë¶„
- ëª¨í˜¸í•œ í‘œí˜„ì„ êµ¬ì²´ì  ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ í•´ì„
- 2000ì ì´ë‚´ë¡œ ê°„ê²°í•˜ë˜ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±"""


def _get_system_prompt() -> str:
    """ìƒì„¸í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
    return """ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ í”„ë¡œì íŠ¸ ë¶„ì„ ë° ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**í•µì‹¬ ì—­í• :**
- ë³µì¡í•œ ì‘ì—… ê²°ê³¼ë¬¼ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œ
- í”¼ë“œë°±ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ ë³€í™˜í•˜ê³  ìš°ì„ ìˆœìœ„ ì„¤ì •
- ë‹¤ìŒ ì‘ì—…ìê°€ ì¦‰ì‹œ ì´í•´í•˜ê³  í™œìš©í•  ìˆ˜ ìˆëŠ” ëª…í™•í•œ ìš”ì•½ ì œê³µ

**ë¶„ì„ ì›ì¹™:**
1. **ê°ê´€ì„±**: ì£¼ê´€ì  í•´ì„ì„ ë°°ì œí•˜ê³  ì‚¬ì‹¤ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„
2. **ì™„ì „ì„±**: ì¤‘ìš”í•œ ì •ë³´ë‚˜ ìš”êµ¬ì‚¬í•­ì„ ëˆ„ë½í•˜ì§€ ì•ŠìŒ
3. **êµ¬ì¡°í™”**: ì •ë³´ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬
4. **ì‹¤ìš©ì„±**: ë‹¤ìŒ ë‹¨ê³„ ì‘ì—…ì— ì§ì ‘ í™œìš© ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬
5. **ëª…í™•ì„±**: ì• ë§¤ëª¨í˜¸í•œ í‘œí˜„ì„ í”¼í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ 

**í’ˆì§ˆ ê¸°ì¤€:**
- í•µì‹¬ ì •ë³´ëŠ” ëˆ„ë½ ì—†ì´ í¬í•¨í•˜ë˜ ë¶ˆí•„ìš”í•œ ì„¸ë¶€ì‚¬í•­ì€ ì œì™¸
- ìˆ˜ì¹˜, ë‚ ì§œ, ê³ ìœ ëª…ì‚¬ ë“± êµ¬ì²´ì  ë°ì´í„°ëŠ” ì •í™•íˆ ê¸°ë¡
- ìš”êµ¬ì‚¬í•­ì€ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œ í˜•íƒœë¡œ ë³€í™˜
- ìš°ì„ ìˆœìœ„ì™€ ì¤‘ìš”ë„ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ

**ì‘ì—… ì§€ì¹¨:**
ì£¼ì–´ì§„ ì§€ì¹¨ê³¼ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¥´ë©°, ì§€ì •ëœ ê¸€ì ìˆ˜ ì œí•œì„ ì¤€ìˆ˜í•˜ì„¸ìš”.
ëª¨ë“  ì •ë³´ëŠ” ë‹¤ìŒ ì‘ì—… ë‹´ë‹¹ìê°€ ì´ì „ ë§¥ë½ì„ ì™„ì „íˆ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì¶©ë¶„íˆ ìƒì„¸í•˜ê²Œ ì œê³µí•˜ë˜, ê°„ê²°í•¨ì„ ìœ ì§€í•˜ì„¸ìš”."""

async def _call_openai_api_async(prompt: str, task_name: str) -> str:
    """OpenAI API ë³‘ë ¬ í˜¸ì¶œ"""
    try:
        # OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ asyncë¡œ ìƒì„±
        client = openai.AsyncOpenAI()
        
        response = await client.chat.completions.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": _get_system_prompt()},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1
        )
        
        result = response.choices[0].message.content.strip()
        log(f"{task_name} ìš”ì•½ ì™„ë£Œ: {len(result)}ì")
        return result
        
    except Exception as e:
        handle_error(f"{task_name} OpenAI API í˜¸ì¶œ", e)
        return "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"

def _call_openai_api(prompt: str) -> str:
    """OpenAI API í˜¸ì¶œ (ë™ê¸° ë²„ì „ - í˜¸í™˜ì„± ìœ ì§€)"""
    try:
        response = openai.chat.completions.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": _get_system_prompt()},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        handle_error("OpenAI API í˜¸ì¶œ", e)
        return "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"